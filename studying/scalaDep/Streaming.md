# Spark Streaming

## 流数据概述
本节内容首先介绍静态数据和流数据的区别，以及针对这两种数据的计算模式，即批量计算和实时计算，然后介绍计算的概念、框架和处理流程。

### 静态数据和流数据
数据总体上分为静态数据和流数据

**1.静态数据**  
很多企业为了支持决策分析而构建的数据仓库（如下图）其中存放的大量历史数据就是静态数据，这些数据来自不同的数据源，利用ETL(Extract-Transform-Load)工具加载到数据仓库中，并且不会发生更新，技术人员可以利用数据挖掘和OLAP(On-Line Analytical Processing)分析工具从这些静态数据中找到对企业有价值的信息。

<img src='./pics/1.png' width="80%">

**2.数据流**  
近年来，在Web应用、网络监控、传感检测、电信金融、生产制造等领域，兴起了一种新的数据密集型应用——流数据，即数据以大量、快速、时变的流形式持续到达。以传感检测为例，在大气中放置PM2.5传感器实时监测大气中的PM2.5的浓度，检测数据会源源不断地实时传输回数据中心，检测系统对回传数据进行实时分析，预判空气质量变化趋势，如果空气质量在未来一段时间内会达到影响人体健康的程度，就启动应急响应机制。

从概念上而言，流数据（或数据流）是指在时间分布和数量上无限的一系列动态数据集合体；数据记录是流数据的最小组成单元。流数据具有以下特征。
- 数据快速持续到达，潜在大小也许是无穷无尽的
- 数据来源众多，格式复杂
- 数据量大，但是不十分关注存储，一旦流数据中的某个元素经过处理，要么被丢弃，那么被归档存储
- 注重数据的整体价值，不过分关注个别数据
- 数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序

### 批量计算和实时计算
对静态数据和流数据的处理，对应着两种截然不同的计算模式：**批量计算**和**实时计算**。批量计算以“静态数据”为对象，可以在很充裕的时间内对海量数据进行批量处理，计算得到有价值的信息。Hadoop就是典型的批处理模型，由HDFS和HBase存放大量的静态数据，由MapReduce负责对海量数据执行批量计算。

<img src='./pics/2.png' width='60%'>

流数据不适合采用批量计算，因为流数据不适合传统的关系模型建模，不能把源源不断的流数据保存到数据库中，流数据被处理后，一部分进入数据库成为静态数据，其他部分则直接被丢弃。传统的关系数据库通常用于满足信息实时交互处理需求。

流数据必须采用实时计算，实时计算最重要的一个需求是能够实时得到计算结果，一般要求响应时间为秒级。当只需要处理少量数据时，实时计算并不是问题；但是，在大数据时代，不仅数据格式复杂、来源众多，而且数据量巨大，这就对实时计算提出了很大的挑战。


### 流计算概念

下图是一个流计算的示意图，流计算平台实时获取来自不同数据源的海量数据，通过实时分析处理，获取有价值的信息。  
<img src='./pics/3.png' width='80%'>

流计算秉承一个基本理念，即数据的价值随着时间的流逝而降低。因此，当事件出现时就应该立即进行处理，而不是缓存起来进行批量处理。为了及时处理流数据，就需要一个低延迟、可扩展、高可靠的处理引擎。对于一个流计算系统来说，它应达到如下需求。 
- 高性能。处理大数据的基本要求，如每秒处理几十万数据
- 海量式。支持TB级甚至是PB级的数据规模
- 实时性。必须保证一个较低的延迟时间
- 分布式。支持大数据的基本架构，必须能够平滑扩展
- 易用性。能够快速进行开发和部署
- 可靠性。能够可靠地处理流数据

针对不同的应用场景，相应的流计算系统会有不同的需求，但是，针对海量数据的流计算，无论在数据采集、数据处理中的都应达到秒级别的要求。

### 流计算框架
- 商业级流计算平台
    - IMB InfoSphere Streams。商业级高级计算平台，可以帮助用户额开发应用程序来快速摄取、分析和关联来自数千个实时源的信息
    - IBM StreamBase。IBM开发的另一款商业流计算系统，在金融部门和政府部门使用

- 开源流计算框架
    - Twitter Storm。免费、开源的分布式实时计算系统，可简单、高效、可靠地处理大量的流数据；阿里巴巴的JStorm，是参考Twitter Storm开发的实时流式计算框架，在网络I/O、线程模型、资源调度、可用性及稳定性上做了持续改进。
    - Yahoo! S4(Simple Scalable Streaming System)。开源流计算平台，是通用的、分布式的、可扩展的、分区容错的、可插拔的流式系统

- 公司为支持自身业务开发的流计算框架
    - Facebook Puma。Facebook使用Puma和HBase相结合来处理实时数据
    - DStream。百度开发的实时流数据计算系统
    - 银河流数据处理平台。淘宝开发的通用流数据实时计算系统
    - Super Mario。基于Erlang语言和Zookeeper模块开发的高性能流数据处理框架

### 流计算处理流程
传统的数据处理流程需要先采集数据并存储在关系型数据库等数据管理系统中，之后用户便可以通过查询操作和数据管理操作进行交互，最终得到查询结果。但是，这样一个流程隐含了两个前提。
- 存储的数据是旧的。当对数据做查询的时候，存储的静态数据已经是过去某一时刻的快照，这些数据在查询时可能已经不具备时效性了。
- 需要用户主动发出查询。也就是说用户是主动发出查询来获取结果。

**1.数据实时采集**
数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟性与稳定可靠性。以日志数据为例，由于分布式集群的广泛应用，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据。

目前有许多互联网公司发布的开源分布式日志采集系统均可满足每秒数百MB的数据采集和传输需求，如Facebook的Scribe、Linkdln的Kafka、阿里巴巴的TimeTunnel，以及基于Hadoop的Chukwa和Flume等。

数据采集系统的基本架构一般有3个部分  
<img src='./pics/4.png' width='80%'>

- Agent:主动采集数据
- Collector：接收多个Agent的数据，并实现有序、可靠、高性能
- Store：存储Collector转发过来的数据

但对流计算来说，一般在Store部分不进行数据的存储，而是将采集的数据直接发送给流计算平台进行实时计算。

**2.数据实时计算**  
数据实时计算阶段对采集的数据进行实时的分析和计算。数据实时计算的流程如下，流处理系统接收数据采集系统不断发来的实时数据，实时地进行分析计算，并反馈实时结果。经流处理系统处理后的数据，可视情况进行存储，以便之后再进行分析计算。在时效性要求较高的场景中，处理之后的数据也可以直接丢弃

<img src='./pics/5.png' width='80%'>

**3.实时查询服务**  
流计算的第三个阶段是实时查询服务，经由流计算框架得出的结果可供用户进行实时查询、展示或储存。传统的数据处理流程，用户需要主动发出查询才能获得想要的结果。而在流处理流程中，实时查询服务可以不断更新结果，并将用户所需的结果实时推送给用户。虽然通过对传统的数据处理系统进行定时查询，也可以实现不断更新结果和结果推送，但通过这样的方式获取的结果，仍然是根据过去某一时刻的数据得到的结果，与实时结果有着本质的区别

由此可见，流处理系统与传统的数据处理系统有如下不同之处：
- 流处理系统处理的是实时的数据，而传统的数据处理系统处理的是预先存储好的静态数据。
- 用户通过流处理系统获取的是实时结果，而通过传统的数据处理获取的是过去某一时刻的结果。并且，流处理系统无需用户主动发出查询，实时查询服务可以主动将实时结果推送给用户。


## Spark Streaming
Spark Streaming是构建在Spark上的实时计算框架，它扩展了Spark处理大规模流式数据的能力。Spark Streaming可结合批处理和交互式查询，因此，可以适用于一些需要对历史数据和实时数据进行结合分析的应用场景

### Spark Streaming设计
Spark Streaming是Spark的核心组件之一，为Spark提供了可拓展、高吞吐、容错的流计算能力。如下图，Spark Streaming可整合多种输入数据源，如Kafka、Flume、HDFS，甚至是普通的TCP套接字。经处理后的数据可存储至文件系统、数据库，或显示在仪表盘里。  
<img src='./pics/6.png' width='80%'>

Spark Streaming的基本原理是将实时输入数据流以时间片（通常在0.5-2秒之间）为单位进行拆分，然后采用Spark引擎类似批处理的方式处理每个时间片数据，执行流程如下图。  
<img src='./pics/7.png' width='80%'>

Spark Streaming最主要的抽象是离散化数据流(Discretized Streaming, DStream)，表示为连续不断的数据流。在内部实现上，Spark Streaming的输入数据按照时间片（如1秒）分成一段一段，每一段数据转换为Spark中的RDD，并且对DStream的操作都最终被变为对相应的RDD的操作。实现如下图所示。  
<img src='./pics/8.png' width='80%'>

### Spark Streaming和Storm的对比
Spark Streaming和Storm最大的区别在于，Spark Streaming无法实现毫秒级的流计算，而Storm可以实现毫秒级响应。  
Spark Streaming无法实现毫秒级的流计算，是因为其将流数据分解为一系列批处理作业，在这个过程中，会产生多个Spark作业，且每一段数据的处理都会经过Spark DAG图分解、任务调度等过程，需要一定的开销，因此，无法实现毫秒级响应。Spark Streaming采用的小批量处理的方式，使得它可以同时兼得批量和实时数据处理的逻辑和算法，因此，方便了一些需要历史数据和实时数据联合分析的特定应用场合

### 从“Hadoop+Storm”架构转向Spark架构
为了能够同时进行批处理与流处理，企业应用中通常会采用“Hadoop+Storm”的架构（也称为Lambda架构）。下图给出了采用Hadoop+Storm部署方式的一个案例，在这种部署架构中，Hadoop和Storm框架部署在资源管理器YARN（或Mesos）之上，接受统一的资源管理和调度，并共享底层的数据存储（HDFS、HBase、Cassandra等）。Hadoop负责对批量历史数据对实时查询和离线分析，而Storm则负责对流数据的实时处理。  
<img src='./pics/9.jpeg' width='80%'>

但是，上述的这种架构部署较为繁琐。由于Spark同时支持批处理与流处理，因此，对于某些类型的企业应用而言，从“Hadoop+Storm”架构转向Spark架构就成为一种很自然的选择。采用Spark架构具有如下优点：
- 实现一键式安装和配置、线程级别的任务监控和告警
- 降低硬件集群、软件维护、任务监控和应用开发的难度
- 便于做成统一的硬件、计算平台资源池

## DStream操作概述
### Spark Streaming工作机制


